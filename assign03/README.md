# CS6650 Fall 2021 Assignment 2

## <a name="github">**GitHub**</a>:

**https://github.com/timegao/cs6650-fa21/tree/main/assign03**

&nbsp;

## **Submission Requirements**:

Submit your work to Canvas Assignment 3 as a pdf document. The document should contain:

> [The URL for your git repo](#github).

> [Create a new folder for your Assignment 3 server code](https://github.com/timegao/cs6650-fa21/tree/main/assign03/src/main/java/server)

> A short description of your [database designs and deployment topologies on AWS](#aws-topology)

> [Test runs](#results) ([command windows](#command), [RMQ management windows showing queue size, send/receive rates](#sqs)) 128, 256 client threads for Step 1 and 2.

> [Test run for 128, 256 clients](#results) ([command windows](#command), [RMQ management windows showing queue size, send/receive rates](#sqs)) with both microservices consuming and writing to the database.

> A brief explanation of your [mitigation strategy](#mitigations) and [results](#results) with 128 256 clients to show their effects.

&nbsp;

## **Introduction**:

Assignment description: https://gortonator.github.io/bsds-6650/assignments-2021/Assignment-3

> This assignment builds on assignment 2. The main aim is to persist the tuples generated by the your client.

> It’s likely that the AWS restrictions on the number of instances you can start will mean you can’t use the load balancer. Feel free to increase capacity of servers - just report what you used for gathering result sand watch your $$s!

&nbsp;

## <a name="design">**Design**</a>:

### Step 1 - Adding a Skier Microservice

> In assignment 2, your consumer created an in-memory hash map to skier and lift ride information.

> Your first task is to modify the consumer to persist the results to a database.

> You are free to choose any database you like. AWS RDS instances like MySQL, DynamoDB, MongoDB, Redis - all good candidates.

> The data model you design in the database should enable queries like:

> “For skier N, how many days have they skied this season?”

> “For skier N, what are the vertical totals for each ski day?”

> “For skier N, show me the lifts they rode on each ski day”

> Whatever database you choose, the challenge is to write to the database ideally as fast as you can consume messages from RabbitMQ. This may be challenging based on the EC2 resources you choose, so experiment required. Run some experiments.

I chose to go with a MySQL database on RDS because it was the easiest to setup. Since we don't know what the queries will look like,
I chose to go with the simplest implementation with relational database and to leave the API work to the next assignment.

> [Test](#results) this configuration by reporting the same results as assignment 2 for 128, 256 clients.

Without mitigation, see [results](#results) without nohup. See [mitigations](#mitigations) for strategies employed.

### Step 2 - Adding a Resorts Microservice

> Next, add a new consumer and database for storing data pertinent to the ski resort. The consumer should ingest the same data as the Skier Microservice. The data model should be designed to answer questions like:

> “How many unique skiers visited resort X on day N?”

> “How many rides on lift N happened on day N?”

> “On day N, show me how many lift rides took place in each hour of the ski day”

> Again, test to see if you can write to the database as quickly as the data is published to RMQ.

For the Resorts Microservice, I've left it as work to do for the next assignment. It is designed exactly the same as the LiftRide microservice.

> [Test](#results) this configuration (without skier microservice) by reporting the same results as assignment 2 for 128, 256 clients

Without mitigation, see [results](#results) without nohup. See [mitigations](#mitigations) for strategies employed.

### Step 3 - Experiments

> First, run [tests](#results) for 128 and 256 with both microservices and see what happens.

> It’s likely you will see significant backlogs in your queues, servlet and maybe even consumers.

> If you do, you have two choices:

> Increase capacity - this means deploying more than free tier instances. Watch the $$s.

Starting from a t2.micro database, I quickly ramped up to a t3.medium database as well as tried using a t3.xlarge database.
From the [results](#results), t3.medium seems to afford enough connections for the throughput coming in. Also from the results,
it seems that 2 instances of t2.micro for consumers and 2 instances of t2.micro for server/producer gets the job done.
I chose to go with a load balancer for more stability and to share load between the server/producers, but one t2.micro is likely enough for single runs.

> Introduce throttling - you could do this e.g. in the client by introducing a throughput-based circuit breaker with exponential backoffs in client POSTs and/or RMQ posts/configuration

Throttle already exists because [SNS only allows for 300 requests per second for FIFO SNS's](https://aws.amazon.com/sns/features/).
When I go beyond the 300 requests per second, the request would error out due to `ThrottlingException` and the request would be canceled.
To handle the 'ThrottlingException', I added an exponentialBackoff method within my `PostRequestTask` class in my client.

### <a name="aws-topology">**AWS Topology**</a>

Instead of sticking with rabbitmq, I decided to learn and experiment with SQS instead. That was admittedly a lot of work, but I did learn a lot.

#### SQS Cons:

- No access to IAM roles means that you have to manually set the aws credentials, which expires every three hours.
- SQS is much more expensive than the free option with rabbitmq and charges you for every million requests.
- Since I went with the FIFO option for SNS and SQS, my requests were throttled to 300 requests per second.
- Bugs with purging queues, which sometimes do not work.
- No option to run the service locally for testing.
- Additional programming required to have working code. The code for rabbitmq is mostly provided, but the code for SQS is not and I have to go through a lot of iterations to have a somewhat working code.

#### SQS Pros:

- More custom tweaking. You can set your own parameters for visibility, deduplication, FIFO vs Standard, etc.
- More transparency with monitoring and graphs.
- Better integration with AWS Lambda, though that'll likely cost you.
- It frees up an EC2 instance, which are valuable given we only have access to 5 total (although I only used 4 and only have needed 3).

I also used RDS for the database, and stuck with 2 EC2 instances for consumers, load balancer with 2 EC2 instances for server/producer.

### <a name="dependencies">**Dependencies**</a>

aws-java-sdk-sqs - SQS dependency.

aws-java-sdk-sns - SNS dependency.

aws-java-sdk-sts - AWS credentials.

mysql-connector-java - MySQL dependency.

HikariCP - HikariCP dependency.

dotenv-java - dotenv for Java variables.

gson - used to serialize and deserialize JSON and Java objects.

commons.cli - used to for Apache options.

slf4j-log4j12 - used to log outputs.

log4j - a dependency for org.slf4j.

slf4j-api - dependency for org.sl4j.

maven-assembly-plugin - used to generate the jar files.

javax.servlet-api - used to create the Servlet.

lombok - used to simplify classes with annotations.

swagger-java-client - used for Swagger Client SDK.

### <a name="commands">**Commands**</a>

I used Apache Options from the [Commons CLI library](https://commons.apache.org/proper/commons-cli/) to write the client according to the specifications.

```
usage: options

-i, --ip <arg> ip address of server

-l, --lifts <arg> number of ski lifts, range 5-60, default 40

-m, --mean <arg> mean number ski lifts per ski rider per day, default 10, max 20

-s, --skiers <arg> number of skier IDs, max 100,000

-t, --threads <arg> number of threads, max 2
```

I used Apache Options from the [Commons CLI library](https://commons.apache.org/proper/commons-cli/) to write the consumer.

```
usage: options

 -q,--queueName <arg>   name of the queue

 -t,--threads <arg>     number of threads
```

&nbsp;

## <a name="mitigations">**Mitigation Stragies**</a>

### Iterations:

1. I started off with an asynchronous `MessageListener` SQS FIFO queue, but it was problematic because it only processed one queue item at a time.

2. I added multithreading to the asynchronous `MessageListener` SQS FIFO queue, but that didn't change the number of messages in flight.

3. I scratched the design SQS FIFO queue and went with a Standard queue instead, which allowed for the number of messages in flight to go higher.
   However, the issue became that there were duplicates because Standard queue is at least once delivery, so it's possible for a queue item to be delivered more than once.

4. I switched back to the FIFO queue because it allows for exactly once delivery. I figured out that I needed to set the deduplication level to `MessageGroupId` and `DeduplicationId`.
   Creating the changes with multithreading allowed for multiple number of messages in flight. Changing the visibility timeout fixed the issue with duplicates.

5. I changed the database from DBCP to HikariCP for faster connections. The connections are set up initially, but limited by the connection pool.

6. I removed the asynchronous `MessageListener` for synchronous batch messaging instead to minimize the number of requests to SQS.
   The messages would be received in one batch, and the `DeleteMessageBatchRequest` would also be in one batch.

7. I upgraded the RDS instance from t2.micro to medium to have more connections. I tested upgrading the consumers and server/producers as well,
   but outside of running the instance multiple times, scaling up doesn't seem to help.

### Strategies:

1. One strategy was to run the program with fresh instances. My [observations](#observations) is that there are thermal limitations associated with the t2.micro chips.

2. Using `nohup` to run the Java program led to vastly faster consumers. Logging takes up CPU bandwidth, so it's much faster to output the log to a file instead. This was the game changer for me because I had logging enabled, which meant that pretty much everything happening on the consumer is logged.

### Bottleneck:

The bottleneck for me is the 300 requests/second limitation for SNS Fifo Topics. To overcome the limitation, I would need to use a Standard SNS Topic.
That would mean I would need to add ways to deduplicate my own queues, which is certainly possible by maintaining a cache.
In my testing, I only achieved about 250 requests/second which is about the limit given that I sleep my thread after hitting the `ThrottlingException`.

&nbsp;

## <a name="results">**Results**</a>

### <a name="commands">**Throughputs**</a>

Throughputs were consistenly around 200 requests per second, going as high as 250 and dropping below 200. The bottleneck was the 300 requests/second limit for SNS FIFO Topics.

#### 256 medium consumers, load balancer, medium database

![256 medium consumers, load balancer, medium database](https://raw.githubusercontent.com/timegao/cs6650-fa21/main/assign03/images/throughput/256%20medium%20lb%20medium.png?token=AMABNPSCKUECFEP34KPTDR3BVP7HM)

#### 256 medium consumers, load balancer, xlarge database

![256 medium consumers, load balancer, xlarge database](https://raw.githubusercontent.com/timegao/cs6650-fa21/main/assign03/images/throughput/256%20medium%20lb%20xlarge.png?token=AMABNPXEZVZBHMWOKYECW4LBVP7GQ)

#### 256 medium consumers, micro server/producer, medium database

![256 medium consumers, micro server/producer, medium database](https://raw.githubusercontent.com/timegao/cs6650-fa21/main/assign03/images/throughput/256%20medium%20micro%20medium.png?token=AMABNPTQIRA7MUTM5KCF7ILBVP7FU)

#### 256 micro consumers, load balancer, medium database with nohup 1

![256 micro consumers, load balancer, medium database with nohup 1](https://raw.githubusercontent.com/timegao/cs6650-fa21/main/assign03/images/throughput/256%20micro%20lb%20medium%201.png?token=AMABNPT6MHMCOQ57ZS5B2HDBVP7E4)

#### 256 micro consumers, load balancer, medium database with nohup 2

![256 micro consumers, load balancer, medium database with nohup 2](https://raw.githubusercontent.com/timegao/cs6650-fa21/main/assign03/images/throughput/256%20micro%20lb%20medium%202.png?token=AMABNPTHBLIVMVCUGNHBTBTBVP7DQ)

#### 256 small consumers, load balancer, medium database

![256 small consumers, load balancer, medium database](https://raw.githubusercontent.com/timegao/cs6650-fa21/main/assign03/images/throughput/256%20small%20lb%20medium.png?token=AMABNPWYFWOSVNFECSCAJU3BVP7AO)

The biggest game changer for me was running the consumer and without `nohup`. The other was grabbing fresh EC2 instances as opposed to running on the same instances, see [observations](#observations) for analysis.

#### 128 micro consumers, load balancer. medium database

The only instance of 128 threads. Despite running at 128 threads instead of 256 threads, the throughput is the same because the bottleneck is SNS FIFO Topics.

![128 micro consumers, load balancer, xlarge database](https://raw.githubusercontent.com/timegao/cs6650-fa21/main/assign03/images/throughput/128%20micro%20lb%20xlarge.png?token=AMABNPQFHUNL3M7UNZBNBN3BVP7J2)

### <a name="sqs">**SQS Windows**</a>

### Resort Queue xlarge database without nohup:

Without `nohup`, the queues are filled over time to as high as over 100k items. Having a consumer bigger than t2.micro did not help past the first instance, and having a database bigger than t3.medium also did not help.

#### 256 small consumer received:

![256 small consumer received](https://raw.githubusercontent.com/timegao/cs6650-fa21/main/assign03/images/resorts/256%20small%20received.png?token=AMABNPXJZITE2AVHUHH4L53BVQAE6)

#### 256 small consumer visible:

![256 small consumer visible](https://raw.githubusercontent.com/timegao/cs6650-fa21/main/assign03/images/resorts/256%20small%20visible.png?token=AMABNPV7ZLWQ33BM52TK3WTBVQAGY)

#### 256 medium consumer received:

![256 medium consumer received](https://raw.githubusercontent.com/timegao/cs6650-fa21/main/assign03/images/resorts/256%20medium%20received.png?token=AMABNPREWJXFDESZCVLYLADBVQAIW)

#### 256 medium consumer visible:

![256 medium consumer visible](https://raw.githubusercontent.com/timegao/cs6650-fa21/main/assign03/images/resorts/256%20medium%20visible.png?token=AMABNPT6IB5E2BSFRXK2OATBVQAKY)

#### 256 xlarge consumer received:

![256 xlarge received](https://raw.githubusercontent.com/timegao/cs6650-fa21/main/assign03/images/resorts/256%20xlarge%20received.png?token=AMABNPTRGI4DGFKSTSJEABLBVP7UO)

#### 256 xlarge consumer visible:

![256 xlarge visible](https://raw.githubusercontent.com/timegao/cs6650-fa21/main/assign03/images/resorts/256%20xlarge%20visible.png?token=AMABNPSYT3UOPLFY6QMGB23BVP7TE)

### Resort Queue medium database with nohup:

Even with a smaller database, by having running the program with `nohup` and refreshing the EC2 instances, the queues were able to keep up.

#### 256 micro received 1:

![256 micro received](https://raw.githubusercontent.com/timegao/cs6650-fa21/main/assign03/images/resorts/256%20micro%20received%20medium%201.png?token=AMABNPXMAIY7HM6SZ4J3PN3BVQAT6)

#### 256 micro visible 1:

Without refreshing the consumer instances, the queues start backing up.

![256 micro visible 1](https://raw.githubusercontent.com/timegao/cs6650-fa21/main/assign03/images/resorts/256%20micro%20visible%20medium%201.png?token=AMABNPWQMCEF5ZA5WOO4NZ3BVQAXE)

#### 256 micro received 2:

![256 micro received 2](https://raw.githubusercontent.com/timegao/cs6650-fa21/main/assign03/images/resorts/256%20micro%20received%20medium%202.png?token=AMABNPRUTWP6EBNM6OMU24LBVQAX6)

#### 256 micro visible 2:

By refreshing the consumer instances and running the program with `nohup`, the queues are no longer backed up.

![256 micro visible 2](https://raw.githubusercontent.com/timegao/cs6650-fa21/main/assign03/images/resorts/256%20micro%20visible%20medium%202.png?token=AMABNPXTSQM2ZTOPFDX3KM3BVQAYQ)

#### 128 micro consumer received:

![128 micro consumer received](https://raw.githubusercontent.com/timegao/cs6650-fa21/main/assign03/images/resorts/128%20micro%20received.png?token=AMABNPTZJONUDM4I4AD7QR3BVQIEW)

#### 128 micro consumer visible:

Depending on the way the processes are run, since HikariCP can only allow so many connections, one consumer may have more connections than the other.
This may lead to unevenness in the queues where one queue performs better than the other because it has more connections.

![128 micro consumer visible](https://raw.githubusercontent.com/timegao/cs6650-fa21/main/assign03/images/resorts/128%20micro%20visible.png?token=AMABNPSZJA4CYDFGVAH2IC3BVQIF4)

### LiftRide Queue xlarge database without nohup:

Without `nohup`, the queues are filled over time to as high as over 100k items.

#### 256 small consumer received:

![256 small consumer received](https://raw.githubusercontent.com/timegao/cs6650-fa21/main/assign03/images/liftrides/256%20small%20received.png?token=AMABNPRUBWQ5JBVPE733ZXDBVQBI4)

#### 256 small consumer visible:

![256 small consumer visible](https://raw.githubusercontent.com/timegao/cs6650-fa21/main/assign03/images/liftrides/256%20small%20visible.png?token=AMABNPXZS4BCHHBYGGCPX2DBVQBJS)

#### 256 medium consumer received:

![256 medium consumer received](https://raw.githubusercontent.com/timegao/cs6650-fa21/main/assign03/images/liftrides/256%20medium%20received.png?token=AMABNPSMWPL265BRLXYRQV3BVQBNQ)

#### 256 medium consumer visible:

![256 medium consumer visible](https://raw.githubusercontent.com/timegao/cs6650-fa21/main/assign03/images/liftrides/256%20medium%20visible.png?token=AMABNPWFVULM2V43EOFTBM3BVQBOO)

#### 256 xlarge consumer received:

![256 xlarge received](https://raw.githubusercontent.com/timegao/cs6650-fa21/main/assign03/images/liftrides/256%20xlarge%20received.png?token=AMABNPUAV7LLLERA2AQMBKTBVQBLC)

#### 256 xlarge consumer visible:

![256 xlarge visible](https://raw.githubusercontent.com/timegao/cs6650-fa21/main/assign03/images/liftrides/256%20xlarge%20visible.png?token=AMABNPUSJVDBIG3HSNQ2UYDBVQBMK)

### LiftRide Queue medium database with nohup:

Even with a smaller database, by having running the program with `nohup` and refreshing the EC2 instances, the instances are no longer backed up.

#### 256 micro received 1:

![256 micro received](hhttps://raw.githubusercontent.com/timegao/cs6650-fa21/main/assign03/images/liftrides/256%20micro%20received%20medium%201.png?token=AMABNPSGMT7GO4E776XLJ3DBVQBRK)

#### 256 micro visible 1:

Without refreshing the consumer instances, the queues start backing up.

![256 micro visible 1](https://raw.githubusercontent.com/timegao/cs6650-fa21/main/assign03/images/liftrides/256%20micro%20visible%20medium%201.png?token=AMABNPWJ23E4523U45DG7OTBVQBSG)

#### 256 micro received 2:

![256 micro received 2](https://raw.githubusercontent.com/timegao/cs6650-fa21/main/assign03/images/liftrides/256%20micro%20received%20medium%202.png?token=AMABNPUQHKYGCZIQKOEGCJDBVQBS4)

#### 256 micro visible 2:

By refreshing the consumer instances, the queues are no longer backed up.

![256 micro visible 2](https://raw.githubusercontent.com/timegao/cs6650-fa21/main/assign03/images/liftrides/256%20micro%20visible%20medium%202.png?token=AMABNPUZP2P65V2QE2I3JE3BVQBT6)

#### 128 micro consumer received:

![128 micro consumer received](https://raw.githubusercontent.com/timegao/cs6650-fa21/main/assign03/images/liftrides/128%20micro%20received.png?token=AMABNPXKMUPDPDS3VRI5DHDBVQICI)

#### 128 micro consumer visible:

![128 micro consumer visible](https://raw.githubusercontent.com/timegao/cs6650-fa21/main/assign03/images/liftrides/128%20micro%20visible.png?token=AMABNPWHYLF26FDG2K5ZV6TBVQIDQ)

&nbsp;

### <a name="observations">**Observations**</a>

There appears to be thermal limitations on the AWS CPU's where running the same task one after the other could vastly affect the results.
This is understandable because chips inevitably get hot after running full throttle for 10+ minutes at a time,
and the cooling solution for these low power chips might not be very good. t2.micro chips are from 2013, which is ancient in today's terms.
t3.micro is much better suited for multi-threaded web servers with 2 cores instead of 1 for t2.micro and 9.31 GB/s memory bandwith instead of t2.micro's 15.5 GB/s.
Unfortunately AWS doesn't let you create EC2 instances from AMI's. For the very result, I found it better to switch EC2 instances after every run.
Even after waiting for as long as 30 minutes, the chips have not cooled down enough for an effective second run.

#### first run:

The first run handles the requests as expected, and visible messages doesn't go much beyond 70 at the peak of about 17,000 messages received per second.

![first run received](https://raw.githubusercontent.com/timegao/cs6650-fa21/main/assign03/images/liftrides/256%20micro%20received%20medium%202.png?token=AMABNPXPG7SEQJA3DJQKVFDBVPWT2)

![first run visible](https://raw.githubusercontent.com/timegao/cs6650-fa21/main/assign03/images/liftrides/256%20micro%20visible%20medium%202.png?token=AMABNPSPZJF7P2RQM3CX6H3BVPWSA)

#### second run:

The second run starts handling the requests as soon as the message received reaches the peak, and never quite recovers after that, hitting as high as about 110k visible messages.

![second run received](https://raw.githubusercontent.com/timegao/cs6650-fa21/main/assign03/images/liftrides/256%20micro%20received%20medium%201.png?token=AMABNPVGTCXJZOQCBXM4YPTBVPWTA)

![second run visible](https://raw.githubusercontent.com/timegao/cs6650-fa21/main/assign03/images/liftrides/256%20micro%20visible%20medium%201.png?token=AMABNPS2TOO3WOBJV7DRPPDBVPWQU)

#### notes:

Because the server drastically slows down by the second run, I'm unable to collect the data.
However, my testing is that running the server again on the same t2.micro instances would lead to drastically slower results,
where the server can dip to as low as 10 requests per second and thus it may take hours to finish. I simply don't have the time to just let it run.

&nbsp;

## <a name="uml">**UML**</a>

### server/producer

![server_producer uml](https://raw.githubusercontent.com/timegao/cs6650-fa21/main/assign03/images/uml/server_producer.png?token=AMABNPVYMKBQMR56NZHSCFDBVPWJU)

### consumer

![consumer uml](https://raw.githubusercontent.com/timegao/cs6650-fa21/main/assign03/images/uml/consumer.png?token=AMABNPXBJ36X2WLSTRZHBM3BVPV7G)
